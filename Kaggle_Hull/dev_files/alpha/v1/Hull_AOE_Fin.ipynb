{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =========================================================================================\n",
    "### TITLE: Hull Tactical - Gen5 Lean & Fast (Optimized)\n",
    "### AUTHOR: AI Machine Learning Engineer\n",
    "### DESCRIPTION:\n",
    "### Optimized \"Lean\" version of the Hull Tactical strategy.\n",
    "### \n",
    "### CHANGES:\n",
    "### 1. **Signal-to-Noise**: Removed noisy indicators (KDJ, BB).\n",
    "### 2. **Fast Regime**: Switched to 5d/22d volatility ratio for instant reaction.\n",
    "### 3. **Regularization**: Increased LightGBM regularization to prevent overfitting.\n",
    "### ========================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "import kaggle_evaluation.default_inference_server\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class Config:\n",
    "    SEED = 42\n",
    "    \n",
    "    # Regime-Adaptive Weights\n",
    "    # Adjusted for faster reaction\n",
    "    DEFENSIVE_W_LINEAR = 0.7\n",
    "    DEFENSIVE_W_TREE = 0.3\n",
    "    \n",
    "    NORMAL_W_LINEAR = 0.4\n",
    "    NORMAL_W_TREE = 0.6\n",
    "    \n",
    "    # Volatility Targeting\n",
    "    TARGET_VOL = 0.005\n",
    "    MAX_LEVERAGE = 2.0\n",
    "    \n",
    "    # Online Learning Rate\n",
    "    SGD_LR = 0.001"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# REPLACE THE FEATURE ENGINEERING SECTION WITH THIS LEAN VERSION\n",
    "\n",
    "def feature_engineering(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    targets = ['forward_returns', 'risk_free_rate']\n",
    "\n",
    "    # 1. Lags (The most predictive features)\n",
    "    for col in targets:\n",
    "        for lag in [1, 2, 3, 5, 10]:\n",
    "            df[f'lag_{col}_{lag}'] = df[col].shift(lag)\n",
    "\n",
    "    # 2. Volatility (The Risk features)\n",
    "    base_col = 'lag_forward_returns_1'\n",
    "    df['vol_5d'] = df[base_col].rolling(5).std()\n",
    "    df['vol_22d'] = df[base_col].rolling(22).std()\n",
    "\n",
    "    # 3. Momentum (The Trend features)\n",
    "    df['mom_5d'] = df[base_col].rolling(5).mean()\n",
    "    df['mom_22d'] = df[base_col].rolling(22).mean()\n",
    "\n",
    "    # 4. Lean Technicals (Only the robust ones)\n",
    "    # EMA for Trend Direction\n",
    "    df['ema_12'] = df[base_col].ewm(span=12, adjust=False).mean()\n",
    "    df['ema_26'] = df[base_col].ewm(span=26, adjust=False).mean()\n",
    "    df['macd'] = df['ema_12'] - df['ema_26'] # Standard MACD Line\n",
    "\n",
    "    # RSI for Overbought/Oversold (Normalized 0-100)\n",
    "    delta = df[base_col].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "    rs = gain / (loss + 1e-10)\n",
    "    df['rsi'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    # 5. Fast Regime Signal (Weekly vs Monthly)\n",
    "    # If 5d vol is higher than 22d vol, market is accelerating/panicking\n",
    "    df['vol_ratio'] = df['vol_5d'] / (df['vol_22d'] + 1e-8)\n",
    "\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "# ADJUST THE REGIME WEIGHT FUNCTION (Inference Loop)\n",
    "def get_adaptive_weights(vol_ratio):\n",
    "    # Faster reaction: If this week is 20% crazier than the month\n",
    "    if vol_ratio > 1.2:\n",
    "        return 0.7, 0.3 # Defensive: 70% Linear (Trend), 30% Tree\n",
    "    else:\n",
    "        return 0.4, 0.6 # Normal: 40% Linear, 60% Tree"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def load_data(path):\n",
    "    print(f\"Loading {path}...\")\n",
    "    df_pl = pl.read_csv(path)\n",
    "    cols = [c for c in df_pl.columns if c != 'date_id']\n",
    "    df_pl = df_pl.with_columns([pl.col(c).cast(pl.Float64, strict=False).fill_null(0) for c in cols])\n",
    "    return df_pl.to_pandas()\n",
    "\n",
    "# Load Train\n",
    "TRAIN_PATH = \"/kaggle/input/hull-tactical-market-prediction/train.csv\"\n",
    "train_df = load_data(TRAIN_PATH)\n",
    "\n",
    "print(f\"Raw training data: {len(train_df)} rows\")\n",
    "\n",
    "# Apply Engineering\n",
    "train_df = feature_engineering(train_df)\n",
    "\n",
    "# Drop initial NaNs from lags\n",
    "train_df = train_df.iloc[25:].reset_index(drop=True)\n",
    "\n",
    "print(f\"After feature engineering: {len(train_df)} rows\")\n",
    "\n",
    "# Define Columns\n",
    "TARGET = \"forward_returns\"\n",
    "DROP = ['date_id', 'is_scored', 'forward_returns', 'risk_free_rate', 'market_forward_excess_returns']\n",
    "FEATURES = [c for c in train_df.columns if c not in DROP]\n",
    "\n",
    "print(f\"Features Created: {len(FEATURES)}\")\n",
    "print(f\"Training samples available: {len(train_df)}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"Training Hybrid Models...\")\n",
    "\n",
    "X = train_df[FEATURES]\n",
    "y = train_df[TARGET]\n",
    "\n",
    "# MODEL 1: Online Linear Model (SGD)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "linear_model = SGDRegressor(\n",
    "    loss='squared_error', \n",
    "    penalty='l2',\n",
    "    alpha=0.0001,\n",
    "    learning_rate='constant', \n",
    "    eta0=Config.SGD_LR,\n",
    "    max_iter=1000,\n",
    "    tol=1e-4,\n",
    "    random_state=Config.SEED\n",
    ")\n",
    "linear_model.fit(X_scaled, y)\n",
    "\n",
    "# MODEL 2: LightGBM (Tree) - UPDATED REGULARIZATION\n",
    "lgbm_model = LGBMRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=5,\n",
    "    num_leaves=31,\n",
    "    min_child_samples=20,\n",
    "    subsample=0.8,\n",
    "    subsample_freq=1,\n",
    "    colsample_bytree=0.5,  # CHANGED from 0.8\n",
    "    reg_alpha=0.1,         # CHANGED from 0.0\n",
    "    reg_lambda=0.01,\n",
    "    random_state=Config.SEED,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "lgbm_model.fit(X, y)\n",
    "\n",
    "print(\"Models Trained Successfully.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"LEAN FEATURE VALIDATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check new features\n",
    "new_features = ['vol_ratio', 'rsi', 'macd', 'vol_5d']\n",
    "print(f\"\u2713 Lean Features Created: {sum([col in train_df.columns for col in new_features])}/{len(new_features)}\")\n",
    "\n",
    "# Sample values\n",
    "print(\"\")\n",
    "print(\"=\" * 80)\n",
    "print(\"SAMPLE FEATURE VALUES (Last Row)\")\n",
    "print(\"=\" * 80)\n",
    "for feat in new_features:\n",
    "    if feat in train_df.columns:\n",
    "        val = train_df[feat].iloc[-1]\n",
    "        print(f\"{feat:20s}: {val:10.6f}\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"\u2713 All features validated successfully!\")\n",
    "print(\"=\" * 80)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------\n",
    "# 5. INFERENCE LOOP (OPTIMIZED)\n",
    "# -----------------------------------------------------------------------------------------\n",
    "\n",
    "# State Variables\n",
    "GLOBAL_HISTORY = train_df.iloc[-100:].copy()  # Keep last 100 days\n",
    "STEP = 0\n",
    "CURRENT_REGIME = 'NORMAL'\n",
    "\n",
    "print(f\"Initial history buffer: {len(GLOBAL_HISTORY)} days\")\n",
    "\n",
    "def predict(test_pl: pl.DataFrame) -> float:\n",
    "    global GLOBAL_HISTORY, STEP, linear_model, scaler, CURRENT_REGIME\n",
    "    \n",
    "    # 1. Process Input (Strict Float Casting)\n",
    "    cols = [c for c in test_pl.columns if c != 'date_id']\n",
    "    test_pl = test_pl.with_columns([pl.col(c).cast(pl.Float64, strict=False).fill_null(0) for c in cols])\n",
    "    test_df_raw = test_pl.to_pandas()\n",
    "    \n",
    "    # 2. Update History & Feature Engineering\n",
    "    GLOBAL_HISTORY = pd.concat([GLOBAL_HISTORY, test_df_raw], axis=0, ignore_index=True)\n",
    "    \n",
    "    # Generate features on the FULL history, then take the last row\n",
    "    full_features = feature_engineering(GLOBAL_HISTORY)\n",
    "    current_features = full_features.iloc[[-1]][FEATURES]\n",
    "    \n",
    "    # 3. REGIME DETECTION (FAST)\n",
    "    if 'vol_ratio' in current_features.columns:\n",
    "        vol_ratio = current_features['vol_ratio'].values[0]\n",
    "    else:\n",
    "        vol_ratio = 1.0 # Default\n",
    "        \n",
    "    w_linear, w_tree = get_adaptive_weights(vol_ratio)\n",
    "    \n",
    "    # Update CURRENT_REGIME for logging\n",
    "    if vol_ratio > 1.2:\n",
    "        CURRENT_REGIME = 'DEFENSIVE'\n",
    "    else:\n",
    "        CURRENT_REGIME = 'NORMAL'\n",
    "    \n",
    "    # 4. Hybrid Prediction\n",
    "    # Linear Prediction\n",
    "    curr_X_scaled = scaler.transform(current_features)\n",
    "    pred_linear = linear_model.predict(curr_X_scaled)[0]\n",
    "    \n",
    "    # Tree Prediction\n",
    "    pred_tree = lgbm_model.predict(current_features)[0]\n",
    "    \n",
    "    # Regime-Adaptive Ensemble\n",
    "    raw_return_pred = (pred_linear * w_linear) + (pred_tree * w_tree)\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # ENHANCED VOLATILITY SCALING\n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    # Get current market volatility\n",
    "    if 'vol_22d' in current_features.columns:\n",
    "        current_vol = current_features['vol_22d'].values[0]\n",
    "    else:\n",
    "        current_vol = 0.005\n",
    "\n",
    "    if current_vol < 1e-6: \n",
    "        current_vol = 0.005\n",
    "        \n",
    "    # Kelly-style Sizing\n",
    "    vol_scalar = Config.TARGET_VOL / current_vol\n",
    "    sign = np.sign(raw_return_pred)\n",
    "    sharpe_forecast = abs(raw_return_pred) / current_vol\n",
    "    \n",
    "    # Base allocation\n",
    "    allocation_size = sharpe_forecast * vol_scalar * 50\n",
    "    \n",
    "    # Final Allocation\n",
    "    allocation = 1.0 + (sign * allocation_size)\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # SAFETY CHECKS\n",
    "    # -------------------------------------------------------------------------\n",
    "    if CURRENT_REGIME == 'DEFENSIVE':\n",
    "        # Cap leverage in volatile markets\n",
    "        if allocation > 1.5:\n",
    "            allocation = 1.5\n",
    "            \n",
    "    # Clip to Competition Limits [0, 2]\n",
    "    allocation = np.clip(allocation, 0.0, 2.0)\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # ONLINE LEARNING (Update Linear Model)\n",
    "    # -------------------------------------------------------------------------\n",
    "    try:\n",
    "        prev_target = test_df_raw['lagged_forward_returns'].values[0] if 'lagged_forward_returns' in test_df_raw.columns else np.nan\n",
    "        \n",
    "        if not np.isnan(prev_target):\n",
    "            prev_features = full_features.iloc[[-2]][FEATURES] if len(full_features) > 1 else current_features\n",
    "            prev_features_scaled = scaler.transform(prev_features)\n",
    "            linear_model.partial_fit(prev_features_scaled, [prev_target])\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # MEMORY MANAGEMENT\n",
    "    # -------------------------------------------------------------------------\n",
    "    if len(GLOBAL_HISTORY) > 200:\n",
    "        GLOBAL_HISTORY = GLOBAL_HISTORY.iloc[-150:].reset_index(drop=True)\n",
    "    \n",
    "    # Increment step counter\n",
    "    STEP += 1\n",
    "    \n",
    "    # Diagnostic logging\n",
    "    if STEP % 100 == 0:\n",
    "        print(f\"Step {STEP} | Regime: {CURRENT_REGIME} | VolRatio: {vol_ratio:.2f} | Alloc: {allocation:.2f}\")\n",
    "    \n",
    "    return allocation"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "inference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway((\"/kaggle/input/hull-tactical-market-prediction/\",))\n",
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\ude80 LEAN OPTIMIZATION COMPLETE\n",
    "The model has been stripped of noisy features and optimized for speed.\n",
    "- **Features**: Lags, Volatility, Momentum, RSI, MACD\n",
    "- **Regime**: Fast 5d/22d Volatility Ratio\n",
    "- **Model**: High-Regularization LightGBM + Online Linear"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14348714,
     "sourceId": 111543,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}